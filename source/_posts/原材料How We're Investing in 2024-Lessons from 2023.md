Summarise the following CONTENT into a brief paragraph of key points, then into briefly highlighted information in a list, choosing an appropriate emoji for each highlight.And What's key takeaways from the below? Make sure follow the language the user use before.
Your output should use the following template 
### Summary
### Highlights
- [Emoji] Bulletpoint

### key takeaways
- [Emoji] Bulletpoint

---

## By GPT4




---

(00:00) 2023年对于芯片和AI相关的一切来说是非凡的一年，每个星期似乎都有关于AI的重大新闻，无论是像Chat GPT这样的软件，还是微软的共驾驶员，还是硬件方面的NVIDIA GPU加速器及其竞争对手，当然还有股市方面，从“七巨头”到AI软件和硬件领域的小型成长股，都出现了疯狂的股市涨势。所以我们决定做一期节目，回顾一下这一年发生的一切，谈谈我们最喜欢的时刻以及它们对我们的钱和投资的意义。时间宝贵，我们马上开始吧。首先要谈的是你的毛衣，我给你的毛衣评分10分。我不知道人们是否能看到，但这其实是一件NASA的丑陋圣诞毛衣，上面有火箭图案。所以，明年我的计划是弄一件相同的，但是是SpaceX的。对于海外的朋友们，谢谢，这是一件很棒的毛衣。是的，你做得很好。想到就在12个月前，(01:05) 其实是在2022年11月，Chat GPT首次进入市场，这一年的发展速度之快令人难以置信。我们有新模型推出，GPT-4、GPT-4 Turbo，都在三月和十一月发布。我们还推出了插件，还有一个应用商店，你可以在那里创建自己的自定义GPT代理。软件的发展速度如此之快，与此同时，围绕着Sam Altman被解雇的混乱也在发生，首先他被董事会解雇，然后加入了微软，接着董事会被解雇并更换，他又回来了。(01:42) 发生了很多事情，我们需要时间来消化这一切。在2023年结束时，当尘埃落定时，你认为OpenAI作为一家公司的状态是什么？你怎么看？这就是我选的那个时刻，我认为我们需要真正反思，因为OpenAI为整个市场做了一些真正重要的事情。我认为我们从未见过任何组织像OpenAI那样快速地发布产品、升级和更新，他们推出了ChatGPT和DALL·E。我认为明年及未来的情况会是，我们将看到其他软件公司和AI公司降低一些障碍，更快速地推出产品。

(02:20) 所以，强调你关于快速推出产品的观点，感觉就像在今年初的第一次公告之后，就有其他公司依托于Chat GPT构建起来，他们利用它，到了开发者日，他们发布的一些内容基本上使这些公司倒闭了。所以，如果你不创新并迅速行动，你就会死，因为他们会比你创新得更快。我同意你的看法，特别是在(02:51) 开始，那些建立在Chat GPT之上的公司基本上是带有花哨提示工程的包装器，它们很快就消失了，因为Chat GPT变得更擅长

理解提示，提示工程变得民主化，甚至商品化。我认为我们现在已经到了大型语言模型的阶段，你可以相当依赖于今天开始你的业务而不会在明天倒闭。现在我们看到谷歌，稍后我们会谈到，以及Anthropic和Claude等其他模型，他们意识到，嘿，我们实际上必须(03:29) 保持相当积极的步伐，让这些模型能够做更多事情，我们还需要在UI/UX上增加新功能，允许客户不仅仅是使用我们的模型，还要快速发布，因为我们的竞争对手正在快速发布，行业的最新水平也在不断变化。稍后我们还会谈到，但NVIDIA的芯片也在转向更快的步伐，所以从A100到H100 GPU之间原本需要两年的时间，现在只需六个月。然后是H20s，然后是Blackwells等等。我的观点是，整个(04:04) AI软件和硬件行业，一个巨大的行业，包括多个子行业，实际上将会加速运转。所以现在，落后六个月意味着与几年前截然不同的事情，就像“天哪，OpenAI动作真快”，这表明公司可以那么快地行动，即使他们有像微软这样的大型稳定的慢速合作伙伴。例如，微软本应是拖累你的因素，而Satya Nadella正好相反，他愿意与那些想要迅速行动的人合作。(04:43) 并在他们自己的产品中，这种情况下是以AI共驾驶员的形式，建立这种速度。

是的，很好你提到了Satya Nadella和那个模式，因为我认为在Sam被解雇和回归的混乱日子里，有一段时间，每个人都要加入微软。我记得说过，我们将以孵化器的方式运行它，将其作为我们公司内的一个公司，并且我们有不扼杀创新的良好记录。我认为他在那里谈到的正是你所说的，也就是如何将像OpenAI这样的公司纳入(05:14) 你的组织，但不用官僚主义减慢其速度，让它仍然以需要的速度运行，以便主导市场。所以我认为，即使在他考虑吸收它为一家公司的那几分钟里，他也热衷于让创新的步伐保持不变，因为这是他们的一个关键竞争优势之一，也是他们的主要区别之一。是的，我认为这会迫使许多其他巨头公司意识到，嘿，我们必须快速行动。谷歌就是一个很好的例子，所以谷歌可能是拥有创新者困境的最大的公司之一，他们在搜索上有垄断地位，但他们终于承认，好吧，这种模式可能在10年内不再适用，10个蓝色链接，我们需要成为其破坏的先锋，用像Gemini这样的东西，否则别人会这样做。现在他们也在快速行动，我认为这只会在2024年加剧，因为现在Sam Altman回到了OpenAI，他们可能会更快地行动，因为董事会不再是(05:14) 组织不应被繁文缛节拖慢，应保持其主导地位所需的速度。我认为，即使在考虑吸收它作为一个公司的那几分钟里，他也热衷于保持创新的速度，因为这是他们的关键优势之一，也是他们的主要区别之一。我认为这将促使许多其他巨头公司意识到，嘿，我们必须快速行动。谷歌就是一个很好的例子。谷歌可能是拥有创新困境的最大的公司之一，他们在搜索领域拥有垄断地位，但现在他们终于承认，这种模式在10年内可能不再适用。他们需要处于其颠覆的前沿，使用像Gemini这样的东西，否则别人会这么做。现在他们也在快速行动，我认为这在2024年只会变得更加明显，因为Sam Altman回归OpenAI后，他们可能会更快地行动，因为董事会不再是新部署和新发展的障碍。

(06:25) 你所说的听起来像是对微软继续保持领导地位到明年非常看好。你认为谷歌能赶上吗？谷歌是AI方面的领导者，看到他们目前在微软后面，感觉很奇怪。我认为，总的来说，事情会因为OpenAI的Sam Altman和微软的Satya Nadella表明，在任何规模上，从OpenAI的770名员工到微软的几十亿名员工，他们都能快速做出重要决策，无论是在部署软件方面还是在治理和公司结构方面。这就是公司大小和你需要做出的大决策的整个范围。

(07:01) 我们将看到的是对愿意快速做出决策的创新者的巨大回报。现在让我们讨论谷歌是否能够快速行动以赶上OpenAI和微软。我认为答案是肯定的。我认为他们将能够缩小差距。不幸的是，Gemini演示受到了一个蓝鸭测试设置的困扰，因为如果你实际阅读那个演示的博客文章，谷歌Gemini与GPT-4相比有非常好的基准测试。这表明，如果你拥有谷歌那样的巨大资源，愿意快速行动，利用DeepMind，利用谷歌最好的AI人才，把他们集中起来，说“嘿，这是我们的目标，去吧”，我认为他们将能够缩小这个差距。

(08:14) 我同意，我认为2023年最令我惊讶的事情之一就是微软在这一领域保持并可能扩大了他们的领先地位。我原以为谷歌很快就会赶上，但有趣的是，这是他们近期历史上第二次搞砸了演示，并因此造成了大量尴尬的报道，甚至股价也因此受到影响。谷歌不缺乏了解AI的聪明人，他们拥有世界上一些最好的AI人才，也不缺钱来解决这样的问题。所以我也希望谷歌能做些什么。最终，我认为消费者会赢，因为这场AI军备竞赛将意味着我们将看到更多创新产品更快地进入市场。

(09:16) 我认为这里的一个重要启示是速度和波动性。速度在于新闻将更快发布，更多产品和服务推出，更多功能，比如ChatGPT和Bard，更多用例，更多垂直市场。因此，我们将看到速度导致的事情，如Bard和Gemini的失误，以及ChatGPT在其初始推出期间所受到的无数批评。这将增加这些股票的波动性。我们将看到股票下跌，然后有人来解决问题，股价反弹，然后下一个问题出现，股价再次下跌，这将是一个波动性循环，我认为人们还没有准备好。这不是宏观经济波动性，而是技术进步波动性。

(10:28) 基于你刚才所说的，你是否仍然认为OpenAI比任何其他大型语言模型都有巨大优势，无论是Anthropic的Claude、谷歌的Gemini还是其他的？你认为他们的领先优势有多大？这是一个棘手的问题。我一开始使用ChatGPT，因为那是最早推出的，然后我了解到如果你使用微软的搜索，如果你使用Bing，它能够做一些生成性AI，并带来实时搜索结果，所以然后我开始使用Bing聊天。然后我了解到Anthropic的Claude可以接受比任何其他人都大的提示，所以我转移到了Claude。但后来ChatGPT推出了订阅版本，可以做所有这些事情和更多，所以我一直在转换工具，看哪个工具为我提供了最好的功能，感觉这一直在变化。

(12:05) 似乎就像是ChatGPT，因为现在它可以接受更大的提示，已经更新到2023年4月的知识，并与实时搜索集成，所以对我来说，截至目前的录制，这是我总是使用的解决方案。但这是一个快速发展的领域，未来几周可能会有一些超越它的东西出现。对我来说，竞争不断提高了最低可接受的性能水平，但ChatGPT，特别是GPT-4、GPT-4 Turbo、GPT-4.5，似乎总是在提高天花板，然后其他人迅速缩小差距。

(13:13) 我们已经讨论了软件方面，现在来谈谈同样爆炸性增长的硬件。从股市运动的角度看，硬件的影响可能更大。例如，录制这个播客时，英伟达(Nvidia)的股价刚刚突破了每股500美元大关，真是疯狂。英伟达和AI真的是今年的大事。他们的数据中心业绩创纪录，硬件公司的利润率惊人，特别是他们的H100芯片。他们即将推出H200芯片。目前唯一限制他们的似乎是台积电(TSMC)的产能不足。2023年他们几乎没有受到挑战，一直独领风骚。最近，AMD发布了Mi 300X芯片，英特尔也举行了AI Everywhere活动。在GPU数据中心领域，这是一个赢家通吃的市场吗？我认为不是。数据中心实际上是技术组合，当新的工作负载出现时，某些解决方案因为其他方案的缺失而显得非常优越。比如，A100和H100在GPU并不重要的时期几乎没有竞争对手。然后，所有的AI工作负载都只能依赖一种芯片。顺便说一下，这始于几年前，当OpenAI与微软合作，开发AI Azure并开始支持GPT和GPT-2。但那时并不为人所知。大型语言模型确实需要GPU才能发展，而GPU制造商就是英伟达。现在这个市场存在了，我们有英特尔的Gouti 2和即将到来的Gouti 3芯片，还有AMD的Mi 300X和Mi 300A。现在的问题是，这个由AI驱动的新市场是否是赢家通吃的市场，因为以前只有一家公司能做到，现在有多家公司可以做到，会发生什么呢？是的，我仍然认为答案是否定的，因为关键在于哪个公司最好，我们只能在最具成本效益的工作负载上运行，因为这是昂贵的芯片，其容量非常宝贵。真正的问题是，哪些工作负载最适合英伟达的GPU？然后从中回推，这些工作负载占所有数据中心工作负载的百分比是多少？这就是我认为决定谁将赢得这个市场的方法。我确实认为，大家还没有意识到AI和生成型AI工作负载在未来18个月将会有多大的影响。

(16:37) GPU市场曾经崩溃，人们说英伟达之所以成功，是因为加密货币挖矿和GPU市场，但它的收入确实在下降。PC GPU是下降的，游戏一直是他们的主要领域，他们在AI方面有所布局，我们知道他们是领导者，但并没有真正的大规模推广。然后我们有了ChatGPT时刻，这彻底改变了整个局面。你认为AMD太晚了吗？有人觉得当Mi 300X出来时，他们已经错过了机会。我不这么认为。

我认为它落后了，但落后并不意味着太晚。首先，它可以很好地完成H100能做的一些事情，这意味着你可以将一些原本直接放在H100上的工作负载转移到Mi30上，你可能会得到类似的价格性能。如果你可以用更少的功率换取更长的运行时间，因为你不关心工作负载，你会使用更便宜的芯片。这不像自动驾驶汽车，一个用户倾向于购买一辆车，所以赢家成为赢家通吃的市场，因为为什么你不买最好最便宜的车，在这种情况下是特斯拉？如果有更好的芯片出现，他们不会删除服务器架，他们会说：“我下一轮扩张时会买更多这些，我会改变我的投资组合组合，朝着新的目标发展”，而不是“卖掉我的旧车买新车，我仍然只拥有一辆车”。需要注意的是，如果你明天想要一块H100，据说要等待12个月才能得到。所以，如果AMD可以在更短的时间内提供不那么好但几乎一样好的东西，你可能会选择它。这就是为什么我认为AMD在2024年将在这个市场中占有一席之地，他们不必是最快的，也不必是最节能或最便宜的，他们在这个市场中有一席之地，他们将从这个市场中占有一部分份额。因此，如果AMD只是说：“你们说得对，英伟达的芯片比我们的好50%，但我们的芯片便宜50%”，显然不是那么简单，因为还有功耗和物理数据中心占地面积的考虑，还有定价策略，不仅仅是计算性能。然后，我想在我们继续之前指出的另一件事情是，今年我们看到了多少紧急发布会，就像即使苹果也被迫在高通的发布会后紧急举行一个“快速恐怖”活动，然后在英伟达的发布会后，我们看到了AMD和英特尔的紧急发布会。我认为这是疯狂的，这在行业中以前是不常见的，这些活动过去需要几个月的时间来计划和准备，人们会排练他们的演讲，他们会精确地表达他们的话。这是非常疯狂的，这是所有速度的另一个功能，事物发展得是如此之快。

这段文字是一个关于投资、特别是关于加密货币和科技股投资的讨论。以下是全文的翻译：

(20:05) 我想让你的观众和社区从这个变化的方向中获得什么？你能不能也谈谈方向变化的原因？和Ark Invest的分手不是一些预先计划好的事情，对吧？实际发生的是我和你决定坚持我们的核心能力，而不是去模仿和评论另一个投资经理。在我看来，Ark Invest真的拥有最好的研究，但在我看来，他们并不擅长将这些研究转化为投资决策。我们非常具体地指出了这些投资决策是什么，比如在Nvidia股价翻三倍之前就抛售它，或者没有认识到来自“七大奇迹”的创新。他们的投资决策中似乎有很多偏见，因为他们只是想与大型指数保持不相关，但这实际上开始影响了他们描述创新的方式，以至于这与我和你的背景不太吻合。所以，这就是我们离开Ark Invest的原因。同时，我确实想坚持我们的核心能力。我认为我和你在AI软硬件方面做得很好。

(21:21) 我确实认为，当Ark Invest在这一领域有所重叠时，特别是对于Ark K、Ark W和RQ这三只基金，我确实想更多地关注他们的研究。我一直说这个，我认为他们拥有市场空间中最好的研究。我只是个人不太同意他们如何将这些研究转化为投资决策。我认为我们可以从今年与Ar invest分手后的表现中看出这一点，我们今年做得很好，对吧？比如我们最大的股票选择是Nvidia，它的股价翻了三倍多。我们第二大的股票选择是微软，Arvest没有持有任何微软股票，他们抛售了很多Nvidia股票。所以我们与他们的分歧相当大。所以你知道，我们会继续这样做，当有意义的时候与他们保持一致，当没有意义的时候不与他们保持一致。愿意沿着这条路走下去的人可以这样做，而不喜欢我们对市场的看法的人，还有很多其他了不起的内容创作者，他们对投资有非常不同的框架。你知道，我认为这很好。我们会得到一个电话，亚历克斯会说我们要改变方向，我们会说：“又是什么？”，但是公平地说，回头看看你是对的。我们在AI领域和芯片领域以及软件方面加倍努力，这已经是过去12个月的重点了。我想给人们一些幕后的了解，我记得我和你在新奥尔良见面，我非常时差，所以大约晚上6点我就睡着了，但早上我精神很好，我喝了咖啡，大约7、8点，我对亚历克斯说：“我有个主意，让我们做这个播客。”我出于某种原因非常自信，这将是一个非常好的主意。我

想可能是咖啡让我振奋起来，你说：“好，让我们这样做。”然后我记得在我们录制第一集前大约半小时，那时我开始怀疑自己。你作为一个单独面对镜头的人拥有如此稳固的观众群，而我到现在为止一直在幕后，所以我不确定会怎样。但是，我真的要感谢大家分享的反馈，评论非常有帮助，它们不仅仅是建设性的，也关于你们想听更多的东西，想让我们专注于什么。但我们会继续这样做，到目前为止这是一段有趣的旅程。


(23:19) 你知道，我们只是在进行这个节目的前几集，我相信明年我们也会在这种形式上创造一些真正有趣的内容。到目前为止，这真的很棒。因此，我确实想要承认我们观众中的一个群体。我们已经从增长股硬转向了我们更有信心和能力的领域，比如股票。确实有人希望我们能覆盖更多的隐藏宝石，覆盖那些有更大增长机会的小型股票，我真的很理解并感激他们。我认为，现在（23:49）利率预计在2024年和2025年下降，你可以期待我们会有更多这方面的内容，但肯定是在我们已经覆盖的领域，比如人工智能公司、软件即服务公司、半导体公司、增强现实和虚拟现实。我认为随着频道增长到近30万订阅者，对我来说，人们获取到好的信息比激动人心的信息更重要。所以，这种转变部分是我们作为频道、内容创作者和更关心给观众增加价值而不是感觉有价值的人的成熟。我认为今年真正的问题是：“什么对观众最好？我们怎样最好地服务观众？什么想法真正适合观众？”这似乎是关注真正以惊人速度改变我们生活的技术，这就是为什么我们所有最喜欢的时刻，无论是硬件还是软件，你知道，在股市上都如此专注于人工智能。我认为频道在这方面做得非常出色，真正专注于这一点，将我们的研究转化为我们相信的投资决策。因此，你知道，这是（25:11）2021年甚至2022年某些股票类型及其表现以及我们转变之后的表现的原因，区别是昼夜。所以我想，对于那些寻找隐藏宝石的人来说，你会发现它们，像我们会更多地覆盖人工智能、软件和硬件方面的内容。但我想我们的目标始终是，从去年开始，首先考虑观众，而不是仅仅为了酷和激动人心。我认为曾经有一段时间，每个人都在寻找增长股，因为利率非常低，他们在寻找下一个大事物，他们试图真正发掘这些隐藏的宝石，不只是他们，风投公司也向这些公司投入了数百万，试图获得他们的资金回报。那是一个不同的时期，而且Co（可能是Covid-19的简称）只是加剧了这一点。你刚才谈到的关于Arc invest对创新的投资真的很有趣。他们的一个主题显然是人工智能是一切的中心，所以他们应该从过去的12个月中受益良多，为什么他们没有呢？一个原因是他们不认为大型股票是从AI中获得好处的地方。我认为他们在这方面一直很固执，不是吗？就像你说的，你不会

从传统股票中获得曝光，也不会从指数中获得大事物，你会得到不同的东西，你会得到创新技术。是的，而且我确实认为，所有好的投资者都愿意在有新数据时改变他们的想法，无论是新的利率还是新技术的出现。如果你还是10年前的投资者，你可能不是一个好的投资者，如果你认为2020年和2021年做得好的事情将是（26:49）2024年和2025年做得好的事情，更不用说2030年和2031年了，那你可能需要做一点灵魂的搜索。我希望这整个播客节目已经充分指出，世界变化迅速，投资者也需要学会快速适应。所以我期待我们下一集的讨论，我们将讨论2024年的预测。我确信那集节目将在12月播出，到1月底时一切都会变得完全错误，但像这样的想法是：事情变化得太快以至于无法预测。我也为那一集感到兴奋。那么，下次见。我是Alex，这是“股票符号你”，我与Arif一起，提醒你，你能做的最好投资是投资于你自己。

---
## By cladue
好的,我会提供完整的中文翻译:

(00:00) 2023年对于所有与芯片和AI相关的事物来说都是不可思议的一年。每周似乎都有关于AI的重大新公告,无论是软件方面的聊天GPT、Microsoft的copilot,还是硬件方面的nvidia GPU加速器及其所有竞争对手,或者是从全息7到更小的成长型股票在AI软件和硬件领域的狂飙。所以我们认为我们应该制作一期节目,坐下来消化一下今年所发生的一切,讨论一下我们最喜欢的时刻,以及它们对我们的投资意味着什么。你的时间很宝贵,所以让我们直接进入主题。

(00:34) 第一件事,我们必须从你的圣诞毛衣开始。我不知道大家能不能看到,这实际上是NASA的丑圣诞毛衣,这里是火箭。所以你知道,我明年的计划是买同一件毛衣,但是SpaceX的。对于大西洋那边的所有人来说,谢谢你,这是一件很棒的圣诞毛衣。是的,你做得很好。

(01:05) 难以相信,就在12个月前,它被宣布对吧?那是2022年11月,Chat GPT第一次进入市场。我的意思是,今年节奏如此之快,我们看到新模型的发布,GPT 4、GPT 4 Turbo,它们在3月和11月。我们看到被发布的插件,我们看到了一个应用商店的发布,你可以创建自己的定制GPT代理。这个软件以如此快的速度在移动,与此同时,我们看到混乱出现在Sam Altman被开除的问题上,首先他被董事会解雇,接着你知道他加入了微软,然后又是董事会被解雇和替换,他又回来了。发生了很多事。感觉我们需要时间来消化所有这一切。

(01:42) 那么当尘埃落定,2023年末,OpenAI作为一家公司的状况你觉得如何?你是如何看待的?我认为OpenAI做了一些对整个市场非常重要的事情。我不认为我们曾经看到过一个组织能像OpenAI的ChatGPT和DALL-E那样快速推出产品更新升级。我认为接下来的一年和未来会发生的是,我们会看到其他软件公司和其他AI公司放低一些界限,更快地推出产品。

(02:20) 为了强调你关于发布速度的观点,感觉在他们年初的首次公告之后,就有其他公司试图建立在Chat GPT的基础之上,利用它,但是到Dev day发布的时候,他们发布的一些内容基本上就像杀死了那些公司。几乎就像如果你不创新和快速迭代的话,你会死,因为他们的创新速度会比你快得多。我认为你是对的,尤其是在开始阶段,建立在Chat GPT基础之上的公司基本上就是利用高级提示编程的包装器。随着Chat GPT在理解提示方面的提高,以及提示编程的民主化甚至商品化,这些公司很快就死了。

(02:51) 我认为我们现在在大型语言模型方面正处于一个几乎你可以相信的不会在第二天就倒闭的阶段,如果你今天启动你的业务的话。现在我们看到谷歌有Bard,我们有Anthropic的Claude,我们不得不保持更新的节奏,关于这些模型能做什么,我们在UI和UX方面添加的新功能,不仅仅是模型本身,我们需要快速发布,因为我们的竞争对手也在快速发布,最先进的技术也在不断发展。

(03:29) 我们后面也会谈到,英伟达的芯片也正在加快节奏。过去A100和H100 GPU之间有两年的间隔,现在只有6个月的周期,H200、H300等等。我的观点是速度会更快。这意味着落后6个月与过去的意义大不相同。就像,我的天,OpenAI 移动得如此之快,这表明公司可以移动得如此之快。

(04:04) 就是这样一个巨大的规模,从仅有770名员工的OpenAI到Microsoft的上万名员工,他们都能够快速做出重要决策,无论是在部署软件还是治理和公司结构方面。这是一个极端的公司大小和需要做出的重大决策的完整范围,无论是在产品还是公司方面,事情都会变得更快。

(04:43) 是的,在那些混乱的日子里,在Sam被解雇和恢复之间的某个时候,曾经有一段时间人人都要加入微软,我记得有人说我们会作为一个孵化器运行它,作为我们公司中的一家公司,我们在这样做而不扼杀创新方面有着良好的记录。我认为他谈论的就是你所说的,那就是如何将一家像OpenAI这样的公司带入你的组织,而不会因官僚主义而放慢速度,仍然以它需要主导的速度运行。我认为即使只有几分钟的时间考虑将它吸收为一家公司,他也急于保持创新步伐,因为这是他们的关键优势之一。

(05:14) 是的,它推动了许多其他甚至庞大的公司意识到,我们必须行动迅速。另一个很好的例子是谷歌。谷歌可能是最大的一个例子,一个有创新者困境的公司,他们在搜索方面占据垄断地位,但在这里,他们终于承认,好吧,这种模式在10年内可能行不通,10个蓝色链接,我们需要站在它的颠覆最前沿,通过诸如Gemini和Bard之类的东西,否则别人会这么做。现在他们也在加快速度行动。我认为这在2024年只会变得更加明显,因为现在Sam Altman回到了OpenAI,他们可能会行动得更快,因为董事会不会成为部署新开发的障碍。

(05:44) 听起来你的意思是所有关于微软继续在下一年保持领导地位的一切都是非常看好的,你对这方面有什么看法?你认为谷歌能赶上来吗?我的意思是,谷歌是AI的代名词,看到他们现在处于二流地位,落后于微软,真的很奇怪。我认为总的来说,由于OpenAI、Sam Altman和萨提亚•纳德拉展示了,不管公司规模有多大,从仅有770名员工的OpenAI到Microsoft数十万名员工,他们都能够快速做出重要决策,无论是部署软件还是治理和公司结构。这就是我们谈到的整个规模范围,以及你需要做出的重大决策,无论是产品还是公司方面,事情都会变得更快。

(06:25) 我同意。我认为2023年对我来说最大的惊喜之一是微软能够保持并可以说是扩大了他们在这一领域的领先地位。我本以为谷歌赶上只是时间问题,但有趣的是,在他们最近的历史中,这是第二次演示他们搞砸了演示,并导致了大量尴尬的报道,但股票也因此受到了打击。谷歌并不缺少理解AI的聪明人,他们拥有一些世界上最大和最好的AI人才。他们也不缺钏,可以解决像这样的问题。所以我也希望谷歌能做些什么,最终我认为消费者将是赢家。因为这场军备竞赛,如果你想把它称为AI,将意味着我们将看到更多创新产品进入市场,更快地进入你早先的观点。我认为我们会在明年这个时候经历的AI将是一个相对于我们目前拥有的巨大进步。我认为你知道这对每个人来说都很令人兴奋。

(07:01) 那么,根据你刚才所说的,你认为投资者今后应该如何考虑这一点呢?我认为最大的收获,或者我这里的重点是速度和波动性。速度的意思是说新闻会传播得更快,会有更多的产品发布,更多的服务发布,更多Chat GPT和Bard等的功能和能力,会有更多的用例,更多的垂直领域等等。结果就是我们会看到速度带来像Bard那样的失误,然后是与Gemini Chat相关的失误。GPT本身也有不少在最初推出时的批评。

(07:38) 所以我认为这将提高这些股票的波动性。我们会看到股票遭受损失,然后会有人出现解决问题,然后股票会反弹,然后下一个事物就会出问题,然后它会遭受损失,这将是一个波动性的循环,我认为人们并不真正为此做好准备。这不是宏观经济波动性,这实际上是技术进步的波动性。现在理解和评估技术风险,理解支撑股票的科学,这是我们这里的专长,它将变得越来越有意义,因为我认为股价的越来越多将由技术的真正进步驱动。

(08:14) 让我根据你刚才说的进行后续,你仍然认为OpenAI与其他任何你选择的大型语言模型相比具有巨大优势吗?无论是人类学的Claude还是谷歌的Gemini。你认为他们的领先优势缩小了多少?或者你认为它根本没有收缩,现在只是有了其他竞争对手?你怎么看?

是的,这是一个棘手的问题。我会分享我的历程,我认为这可能很典型。我从Chat GPT开始,因为那是第一个出现的东西,每个人都在使用它,然后我了解到,如果你使用Microsoft搜索,如果你使用必应,它就能进行一些生成式AI,同时结合实时搜索结果。所以然后我开始使用类似必应聊天之类的东西。然后我了解到人类学的Claude可以接受更大的提示比任何人都多,我就像,好吧,我可以给它提供整个YouTube文字稿,让它来总结,这是我在Chat GPT上做不到的。 所以我就移动着,一直在这些工具之间移动,看哪个工具为我提供最佳功能。但是Chat GPT推出了订阅版本,可以做所有那些事情以及更多其他功能。 所以就像是一个移动的目标,总是有新的出现。

(09:30) 所以它确实感觉像Chat GPT,现在它可以接受更大的提示,它已升级到2023年4月的知识,它已经与必应的实时搜索集成在一起,所以对我来说,就我们录制这个的时候,这仍然是我总是使用的解决方案。但这是一个非常快速变化的空间,在接下来的几周内可能会出现某些东西来打败它!

(09:55) 对我来说,我认为竞争对手不断提高最小可接受性能的下限,但Chat GPT,尤其是GPT 4、GPT 4 Turbo、GPT 4.5,似乎总是在提高天花板,然后每个人都在快速弥合这一差距。所以我确实认为,也许Gemini现在是最前沿的模型,但总的来说,前沿模型和我们称之为其他竞争对手平均水平之间的距离似乎正在变得越来越小。这似乎意味着在未来的一年或者18个月左右,这些大型语言模型将得到完全普及和商品化,无论你如何想象它。

(10:28) 基于你刚才说的,让我后续跟进一下,你是否仍然认为Open AI在任何你选择的大型语言模型方面与微软相比具有巨大优势?无论是人类学的Claude还是谷歌的Gemini。我认为领先优势已经缩小了多少?或者它根本没有收缩?

是的,这是一个棘手的问题。我会分享我的历程,我认为这可能很典型。我从Chat GPT开始,因为那是第一个出现的东西,每个人都在使用它,然后我了解到,如果你使用微软搜索,如果你使用必应,它就能进行一些生成式AI,同时结合实时搜索结果。所以然后我开始使用类似必应聊天之类的东西。然后我了解到人类学的Claude可以接受更大的提示比任何人都多,我就像,好吧,我可以给它提供整个YouTube文字稿,让它来总结,这是我在Chat GPT上做不到的。所以我就在这些工具之间移动,看哪个为我提供最好的功能。 但是Chat GPT推出了订阅版本,可以做所有那些事情以及更多其他功能。 对我来说,就我们录制这个的时候,这仍然是我总是使用的解决方案。

(11:00) 但是它是一个非常快速变化的空间,在接下来的几周内可能会出现某些东西来打败它!对我来说,我认为竞争对手不断提高最小可接受性能的下限,但Chat GPT,尤其是GPT 4、GPT 4 Turbo和GPT 4.5似乎总是在提高最高限度,然后每个人都在快速弥合这一差距。 因此,我确实认为也许Gemini现在是最前沿的模型,但总的来说,前沿模型和我们称之为其他竞争对手的平均水平之间的距离似乎正在变得越来越小。 这似乎意味着在未来的一年左右,这些大型语言模型将得到完全普及和商品化,无论你如何想象它。

(11:44) 我同意。我认为竞争对手不断提高最小可接受的性能下限,但ChatGPT,尤其是GPT-4、GPT-4 Turbo和GPT-4.5似乎总是在提高最高限度,然后每个人都在快速弥合这一差距。因此,我确实认为也许Gemini现在是最前沿的模型,但总的来说,前沿模型和我们称之为其他竞争对手平均水平之间的距离似乎正在变得越来越小。这似乎意味着在未来的一年左右,这些大型语言模型将被完全普及和商品化,无论你如何想象它。

(12:13) 我认为这是一种伟大的思考方式。这就是大多数人真正关心的,并不是你最近推出了多少十亿参数,而是我能用它做什么,它是否给我带来了竞争优势,如果与其他东西相比我使用它。

(12:29) 完全同意,完全同意。非常好,那么我们已经讨论了软件方面,现在让我们谈谈硬件,这同样爆炸性增长,至少从股市波动来看更大。我的意思是,在录制本播客时,英伟达的股票刚刚突破510美元大关,是不是很疯狂。英伟达和AI真的是今年的主题。他们在数据中心领域取得了创纪录的收入和硬件公司难以置信的利润率。他们的H100芯片似乎唯一的限制是实际上更快地拿出H100,这似乎更多的是台积电产能不足的问题,而不是其他任何事情。在2023年,他们基本上是毫无竞争的。

但是AMD在几天前刚刚发布了他们的MI300X,英特尔也举行了人工智能无处不在的活动。那么你如何看待这个市场呢?这是一个赢家通吃的市场吗?在GPU数据中心领域?你有什么看法?

(13:26) 我认为这不是一个赢家通吃的市场,这里的大不同iator是数据中心实际上是技术组合。当它涉及到为许多这些新工作负载提供服务时,一个解决方案在绝对上优于其他所有解决方案,仅仅是因为其他解决方案实际上并不存在。就像A100基本上是无可争议的GPU,H100是一个几乎无可争议的GPU,在GPU不重要的时刻,直到它们变得重要。然后,所有的AI工作负载,它们只有一个芯片可供选择。

(13:58) 所以,我刚才说的事情实际上在几年前就开始了,当OpenAI与微软合作建立类似AI Azure之类的东西,并开始为GPT和GPT-2等提供动力时,它是幕后的,没有人真正在谈论它。大型语言模型确实需要GPU才能起飞,谁是GPU制造商?是英伟达。现在这个市场已经存在,我们看到了英特尔的Gaudi 2和Gaudi 3芯片等公司的加入,我们看到了AMD的MI300X和MI300A。现在的问题是,这个由AI驱动的新市场是否是一个赢家通吃的市场?因为过去只有一家公司能做到这一点,现在多家公司都能做到,会发生什么?

(14:32) 是的,我仍然认为答案是否定的,因为这将是谁做得最好,我们如何只让最符合成本效益的工作负载运行在英伟达的GPU上,然后从那里反向计算出这些工作负载将占据数据中心所有工作负载的百分比。这就是你如何决定谁将赢得这个市场。

(14:56) 我确实认为每个人都还在沉睡,不了解人工智能和生成式人工智能工作负载在未来18个月内会有多大。这是我喜欢你如何简洁地阐述它的方式——这原本不是一个市场,只有一家玩家,我们没有所谓的杀手级应用。

(15:17) 是的,我还记得当GPU市场崩溃时,你知道,人们会说,英伟达之所以成功,是因为加密挖矿和GPU市场,但其收入正在下降——它们的PC GPU收入确实在下降——游戏一直是他们的大事。他们在AI方面做了这档子事,我们知道他们是领导者,但并没有真正的大规模推广,然后我们迎来了ChatGPT时刻,这真的颠覆了整个形势。

(15:43) 你认为AMD来晚了吗?有人觉得当MI 300X推出时,他们已经错过了船。我不这么认为。我有两个原因认为落后并不意味着太晚。首先,它可以很好地完成H100能做的一些事情,这意味着你可以将部分本应直接放在H100上的工作负载卸载到MI30上,如果你不介意像运行时间更长这样的代价的话,你会得到类似的价格性能比。如果基于工作负载你不在乎,那么使用更便宜的芯片是可以的。这不像自动驾驶汽车,一个用户倾向于购买一辆车,所以赢家变成了一个通吃的市场,因为购买最便宜、最好的汽车,在这种情况下是特斯拉,没有理由不这样做。

(16:24) 在这种情况下,如果有更好的芯片,他们不会删除服务器机架,他们会说,好的,我的下一次扩张我将购买更多这些,我将改变我的投资组合比例。我将朝着一个新的目标前进,而不是卖掉旧车买新车。我仍然拥有一辆汽车。

(16:42) 关于英伟达,你应该知道的一件事是,如果你现在想要一个H100,显然需要12个月的交货时间。因此,如果AMD能在更短的时间内为你提供一个不太好但几乎一样好的东西,你可能会选择它,如果你想购买一些并运行自己的业务。这就是为什么我也觉得AMD在2024年将从中分一杯羹,他们不需要是最快的,也不需要是最节能或最便宜的,他们在这个市场上有一席之地,他们将从这个市场中占据一定的份额。

(17:13) 如果AMD只是说,你是对的,英伟达的芯片比我们的好50%,而我们的芯片比他们的便宜50%.这显然没有那么简单,因为这里有功耗方面的考虑,还有数据中心的物理占用空间,这里还有定价战略元素,而不仅仅是计算性能元素。

(17:33) 我想指出的另一件很有意思的事情是,在今年我们看到了多少紧急演示,就像苹果都被迫在高通演示之后进行紧急演示,然后在英伟达演示之后,我们看到AMD和英特尔的紧急演示。 我认为这简直疯了,这在这个行业里以前不是这样的。就像这些事件过去需要花费数月的时间来计划、准备,人们会排练他们的演讲,他们会掌握每一个词。今年的速度实在是太快了。



(18:06)这又回到了之前关于一切速度的论点。正如你所说的,这对2024年似乎是一个很好的配方。

当我们结束这一年时,我认为我们要涵盖的最后一个领域是频道本身。回顾一下今年的频道,我们进行了一些改变,你令人难以置信地与ARK Invest分手,我们将重点缩小到AI软件公司、半导体公司,这是频道的一个关键重点。我们还推出了不同的格式,比如我们现在的播客,更多的是关于特定事件的精华剪辑。关于改变方向,你真的希望tiemba你的观众和社区带走什么,你能谈谈这种变化吗?

(18:44) 与ARK Invest分手不是预先计划的事情。实际上发生的是,我和你决定坚持我们的核心竞争力,而不是Mirror和评论另一个投资组合经理的投资组合。在我看来,ARK Invest确实拥有市场上最好的研究,但在我看来,他们在将该研究转化为投资决策方面并不出色。我们非常具体地指出了这些投资决策,例如在视频股价翻两番之前抛售英伟达,或没能认识到来自全息7的创新。

(19:15) 似乎有很多这种偏见,这似乎是因为他们只是想与更大的指数保持不相关,但这实际上开始影响他们对整体创新的描述,以至于与我和你以及我们的背景不符。这才真正促使我们远离ARK。同时,我确实想坚持我们的核心竞争力。我认为人工智能软件和硬件方面,我和你一起做得非常出色。

(19:40) 我确实认为,当ARK投资与我们所在的空间重叠时,特别是Ark K、Ark W和Ark Q这三只基金,我确实想多涵盖他们的研究。我一直说,我认为他们的研究整体来说是市场上最好的。我个人不一定同意他们如何将研究转化为投资决策。我认为我们今年与ARK Invest分手后,我们的表现已经验证了这一点。我们最大的股票选择是英伟达,它的价格涨幅超过两倍。我们的第二大股票选择是微软,Ark Invest根本不持有任何微软股票,他们还抛售了很多英伟达股票。

(20:13) 所以我们的决策与他们有很大不同。我认为你知道,对于那些希望我们涵盖更多隐藏小型股票、增长机会更大的股票的人,我真的理解和欣赏这种想法。随着2024年和2025年利率计划下降,你可以期待我们做更多这方面的工作,但肯定是在我们已经涵盖的领域,人工智能软件、服务型软件公司、半导体公司、增强现实和虚拟现实公司。

(20:40) 随着该频道接近30万订阅者,确保人们获得好的信息比兴奋的信息更重要。我认为我们成为频道和内容创作者成长的一部分是我们变得更加成熟,我们更关心为观众增加价值,而不是感到自己很有价值。我认为今年真正的情况是,对观众最有益的是什么,我们如何最好地为观众服务,什么想法对观众真的有意义,这似乎是非常关注人工智能的技术,它们以破纪录的速度改变着我们的生活。

(21:13) 我认为该频道在真正超级关注这一件事情上做得非常出色,将我们的研究转化为我们相信的投资决策。结果,如果您查看2021年和2022年部分时间内的股票及其表现类型以及我们调整后的表现,那是截然不同的。所以你知道,对于那些寻找隐藏小型股票的人,在人工智能软件和硬件领域,你会发现他们,我们会更多地报道他们,但我们的目标始终是我认为从去年开始考虑观众第一,而不仅仅是为了酷和激动人心。

(21:44) 我认为曾几何时,当利率非常低时,人人都在寻找增长型股票,因为人人都在寻找下一个大事件,他们都在努力发掘这些隐藏的小宝石,这不仅仅是他们,风险投资公司也在这些公司中注入了数百万美元,试图从他们的钱中获得回报。那是不同的时代,新冠病毒只会加重这种情况。

(22:10) 但真正有趣的是,你刚才谈到的关于ARK投资和创新的内容。有一個主题,他们非常看好的就是人工智能无所不在,所以他们应该从过去的12个月中受益匪浅。为什么他们没有?一是因为他们不相信巨头能从人工智能中获得利益,我想这一点他们相当教条。就像你所说的,你不会从传统股票和大公司中获得曝光,你会获得不同的东西,你会获得创新,创业公司。

(22:38) 而且我认为所有的好投资者都有一个共同点,那就是随着新数据的出现,他们愿意改变主意。无论是新利率,还是崭新的技术出现,如果你跟10年前的投资者一样,你可能不是一个好的投资者,你可能需要做一些自我反思,如果你认为在2020年和2021年表现不错的东西,会在2024年和2025年,甚至2030年和2031年同样表现不错。

(23:05) 正如这整个播客剧集充分点出的那样,世界正在以破纪录的速度移动,投资者也需要学习如何快速移动。所以我非常期待我们的下一集,我们会谈论2024年的预测。我敢肯定,当这一集在1月底出来时,到了1月底,所有内容都会完全错误。但其中的想法是,事情是否正在以太快的速度前进,以至于我们甚至无法预测。所以我也非常期待那一集。在此之前,这里是Tiker符号,我是Alex,我和Arif一起提醒您,您可以做出的最佳投资是投资于您自己。


--- 
### Origin
E4: How We're Investing in 2024 & Lessons from 2023 - YouTube https://www.youtube.com/watch?v=QoYmhCrAflE Transcript: (00:00) 2023 has been an incredible year for all things related to chips and AI it's felt like every single week There's Been major new announcements on AI whether that's the software side with things like chat GPT Microsoft's co-pilots on the hardware side we have nvidia's gpus accelerators and all of their competition and on the stock market side obviously an insane rally across all tech stocks from the Magnificent 7 all the way down to smaller growth stocks in the AI software and Hardware space so we figured we would put together a episode to just sit back digest everything that's happened over the Year talk about (00:34) our favorite moments and what they might mean for our money and our investments going forward your time is valuable so let's get right into it all right item number one is we have to start with your jumper so that I think you 10 out of 10 for on the jumper there I don't know if people can see this but it's actually a NASA ugly Christmas sweater and these are Rockets right here so you know next year my plan is to get the same one but SpaceX and for everyone across the pond thank you it's a wonder ful jumper so yeah you've done well it's incredible to think it was just 12 months ago that it (01:05) was announced right it was November 2022 that chat GPT first hit the market and I mean this year there's been such a fast pace of everything we had new models coming out GPT 4 gp4 Turbo they were in March and then November we've had plugins that were being released we've had an App Store that was also released where you can create your own custom GPT agents the software was moving at such a fast pace and at the same time we had the chaos around Sam mman being fired first he had been fired by the board then the next thing he knew he was joining Microsoft then it was that the board was being fired and replaced and (01:42) he was coming back much has gone on it feels like we need time to try and digest all of that so where would you say we are at the end of 2023 when the dust settles like where is the state of open AI as a company how do you see it so this was like the moment that I picked that I thought we need to really reflect on because open aai did a few really important things for the entire Market I don't think we've ever seen an organization ship products releases upgrades updates anywhere near as fast as open AI with Chachi PT and Dolly and I think what's going to happen next year and in the future out of that is we'll (02:20) see other software companies and other AI companies lower some of the boundaries and ship faster right so to underline your point about the speed of shipping it felt like after their first announcements at the start of the Year there were other companies that were built off the back of chat GPT that were leveraging it and by the time Dev day came out some of what they released basically like killed those companies off so it was almost like if you don't innovate and quickly you're going to be dead because they're going to have innovated so much faster than you I think you're right that especially in (02:51) the beginning companies that got built on top of chat GPT basically rappers with fancy prompt engineering going on in the background they died off pretty quick as chat GPD got better at understanding prompts as prompt engineering got democratized and even uh commoditized so I think we're getting to a point now in large language models where you can pretty much rely on not going out of business tomorrow if you start your business today right we're seeing Google Now which we'll talk about a little later with Gemini and anthropic with Claude and all these other models now they realize hey we we actually have (03:29) to keep up a pretty aggressive Cadence of how much these models can do what new features we add on top of the uiux all the different things we allow customers to do with our models not just the models themselves we need to ship fast because our competitors are shipping fast and the state-of-the-art is constantly moving we're going to talk about this later too but nvidia's chips are also moving to a faster Cadence so what used to take two years between the a100 and the h100 gpus is now just a six-month cycle the h20s then the Blackwells and so on right so my point about speed is the industry the actual (04:04) AI software and Hardware industry huge industry multiple sub Industries to that is actually going to be moving faster right so now being that means being six months behind on something is very different than what that used to mean a couple years ago just like holy crap open AI moves fast which just shows that companies can move that fast right even when they have big stable slow mon I thic Partners like Microsoft for example Microsoft you would expect to be something that weighs you down and SAA nadela has shown us just the opposite that he's willing to partner with people who want to move aggressively fast and (04:43) build that speed into their own products in this case in the form of AI co-pilots right um yeah it's it's nice that you talked about sat and that model because I think somewhere in the mess of those days between Sam being fired and coming back there was a time when everyone was going to join Microsoft and I remember saying specific Al we will run that as an incubator we'll run it as a company within our company and we have a proven track record of doing that without killing the Innovation and I think what he was talking about there is exactly what you were saying which is how do you bring a company like open AI into your (05:14) organization but not slow it down with the red tape allow it to still run at the speed it needs to to dominate so I think he even for the few minutes where he was thinking of absorbing it as a company was also Keen to allow the pace of innovation to stay because that's one of their key kind of you know silver bullets or one of the key differentiates is that pace yeah and I think it's going to push a lot of other even gigantic companies to realize hey we have to move fast another great example of that is Google so Google is probably one of the biggest examples of a company that has the innovators dilemma they have a (05:48) monopoly on search but here they are finally acknowledging okay this model may not work in 10 years 10 Blue Links we need to be at the Forefront of its disruption with things like Gemini barred or else somebody else will and now they are also moving fast and that's I think only going to be even more exacerbated in 2024 because now that Sam alman's back in open AI they can probably move faster because the board isn't a speed bump on the way to new deployments new developments it sounds like what you're saying is everything's really bullish on Microsoft like continuing this leadership into the next (06:25) year like what what do you see on that front do you think Google can catch up I mean Google is the AI it's really weird to see them playing like second FID or coming second to Microsoft at the moment I think that in general things will move faster because open AI Sam Alman and SAA nadela showed that at any scale from open AI at 770 employees to Microsoft's seven gajillion employees are able to make important decisions quickly both in terms of deploying software and in terms of governance and Company structure that's it that's like the entire spectrum of size of companies and the the entire spectrum of big decisions you (07:01) need to make both in terms of product and in terms of company things will get faster and that's bad for people who can't move fast and great for companies that can and I think what we're going to see is a big reward for innovators that are willing to make decisions fast now let's talk about whether Google can move fast enough to catch up to open Ai and Microsoft right I think the answer is yes I think they'll be able to close the gap it's unfortunate that the Gemini demo is plagued by like the setup of the one Blue Duck test because if you actually read the blog post for that demo Google Gemini has really good (07:38) benchmarks versus GPT 4 what that points to is if you have the giant resources that Google has and you're willing to move fast leverage Deep Mind leverage the best AI Minds at Google slam them together and say hey here's our objective go I think they will be able to close that Gap they have a huge incentive here right which is to defend their search business or be the one to disrupt it with their own large language model and I think they're doing a good job of finally opening their eyes and realizing hey we have to compete here and the competition moves fast back to the earlier point so we must move fast (08:14) even though we're a giant ship yeah I agree I agree I think it one of the surprises of 2023 for me has been that Microsoft has maintained and arguably extended their lead in this area I thought it was just a matter of time before like Google caught up but funnily enough it's the second demo in their recent history I can remember where they've messed up a demo and it's caused loads of embarrassing coverage but also the stock has suffered as a result as well it's not like they're short of smart people at Google who understand AI they've got some of the biggest best AI people in the world and and they're not (08:44) short of cash to be able to throw out a problem like this so I'm I'm also hopeful that Google will do something and ultimately I think the consumer will win really because this this arms race if you want to call it that with AI would just mean we will see more Innovative product come into Market Market kind of quicker to your earlier points I think it will be like the AI that we're experiencing this time next year will be a big step up from what we have currently and I think you know that's in exciting for for everyone um how do you think investors should think about this kind of going forward then so (09:16) I I think the big takeaway here for me for sure is that speed and volatility thing right speed in the sense that news is going to come out way faster more product launches more service launches more capabilities and things like chat GPT and bard more use cases more verticals right and as a result we're going to see that speed result in things like the Goofs that happen with Bard and then the Goof that happened with Gemini chat GPT has no shortage of criticisms uh that it had during its initial roll out and so that will I think increase the volatility of these stocks we're going to see stocks suffer and then (09:53) someone's going to come along and fix a thing and then the stock will rally and then the next thing will break and then it'll suffer and it'll be the cycle of volatility that I think people are not really ready for it's not macroeconomic volatility it's actually technological progress volatility and now understanding and assessing technical risk understanding the science behind the stocks which is our specialty here like it's going to become more and more meaningful because more and more of the stock price I think will be driven by genuine advances in advanced technology let me uh follow up on that just based (10:28) on what you just said do you still think that open AI has a big advantage over any other large language model of your choice whether it's anthropic with Claude Google with Gemini how much do you think that their head start has shrunk or do you think it's not shrunk at all and it's just that there are other players in the field now what do you think yeah it's a tricky one I started so I'll I'll share my journey and I think this might be typical right I started with chat GPT because that was the first thing that came out everyone used that then I learned that if you use Microsoft search if you used Bing that (10:59) was able to to do a bit of generative AI plus bring in real-time search results so then I started using like Bing chat then I learned that anthropics Claude could take a much bigger prompt than anyone else I was like right I can feed it an entire YouTube transcript and get it to summarize that which was I wasn't able to do in chat GPT so I moved I was moving around and then chat GPT came out with a subscription version that did all of that and more stuff so I've been kind of like moving around to which tool provides me the best capability and it feels like that's been a bit of a moving Target and you know there's new ones (11:30) popping up all the time so um it does feel like chat GPT because now it can take a much bigger prompt and it's been brought up to date with uh Knowledge from April 2023 and it's integrated with life search like that for me right now as of recording this is the the solution I always go to but it's a really fast moving space something could come out in the next few weeks that beats it yeah for me I think the competition is constantly raising the lowest acceptable amount of performance but but chat GPT specifically GPT 4 gp4 Turbo GPT 4. (12:05) 5 seems to always be raising the ceiling and then everyone is quickly closing that Gap right so I do think that maybe maybe right now Gemini is the Frontier Model right but in general the distance between the Frontier Model and the Baseline whatever we're calling the the rest of the competition's average seems to be getting smaller and smaller which seems to be pointing to by this time next year or maybe 18 months from now or whatever these large language models will be fully democratized commoditized however you want to think about it to the point where the advantage won't be in which model is better it's which (12:42) model is more user friendly which model has the capabilities that are right for me which models are the easiest to prompt engineer Which models are the easiest to extend with third party Integrations and plugins I think we're we're going to move to a paradigm in the next 12 months where ahead means something different not bigger but more extendable I think that's a great way to think about it that's what people really care about not how many billion parameters you've just rolled out in your latest one it's like what can I do with it does that give me a competitive Advantage if I'm using that versus (13:13) something else totally agree totally agree great so we've covered the software side of it now let's talk about the hardware which has being equally as explosive and from a stock market movement point of you it's probably been even bigger I mean as of recording this podcast Nvidia has just crossed the 5 $100 Mark for the stock something insane so yeah Nvidia and AI really has been the story of the of the year so they had record data center earnings and huge margins for a hardware company incredible margins around their H 100 chips they've got h200 coming in the near future um the only thing limiting them seems to be the the actual (13:51) getting the h100s out quick enough and that really seems to be more about tsmc's lack of capacity more than anything else they've been pretty much un tested in 2023 they've had it all their own way so um we've just had AMD have a a launch of their Mi 300X a few days ago we had Intel's AI everywhere event how do you see the market is this a winner takes all marker in terms of the GPU data center area what are your thoughts I think this is not a winner take all market and I think the big uh differentiator here is data centers are really portfolios of Technologies right what actually happened was when it came (14:32) to servicing a lot of these new workloads one solution was absolutely superior to the rest simply because the rest didn't exist right like the a100 was a virtually uncontested GPU the h100 was a virtually uncontested GPU in a moment where gpus didn't matter until they did right and then what happened was all these AI workloads they only had one chip to turn to right so and that by the way what I'm saying now actually started a few years ago when open AI worked with Microsoft to build out like AI Azure and start powering GPT and gpt2 you know but it was sort of behind the scenes nobody was really talking about (15:13) it right large language models really need gpus to take off who's the GPU maker it's Nvidia right now that that market exists we have entrance like Intel's gouty 2 and soon gouty 3 chip we have uh amds Mi 300X and Mi 300a and now the question is is this new AI driven Market a win or take all Market because it used to be there's only one company that could do it now that multiple companies can do it what happens right yep I still think the answer is no because it's going to be who's the best how can we get only the workloads that are most cost effective to run on there because this is an expensive chip and (15:57) its capacity is at a premium and so the real question is what workloads make the most sense on nvidia's gpus right and then back calculate from there what percentage of all data center workloads will that be and that is how you decide like who's going to win this Market in my opinion I do think that everyone is still sleeping on how big Ai and generative AI workloads are going to be in the next 18 months and it's it's I love how starkly you put it this wasn't a market there was only one player in it and we didn't have that killer app if you like for AI yeah it was always I remember when the (16:37) GPU Market collapsed like you know people were saying well Nvidia was successful because of crypto Mining and the GPU Market but its revenues are declining which they were they literally yeah the PC gpus right they were lit yeah PC gpus were like literally declining gaming had been their big thing they had this AI play we knew there were a leader in there but there wasn't really a massive upsell and then we had had the chat GPT moment which really turned the whole thing on his head do you think AMD is too late some people feel like when the Mi 300X came out it's come out like yeah they've already missed the boat I don't think so (17:10) I think it's behind um but there's there's two reasons why behind doesn't mean too late first it can do some of the things that the h100 can do very well which means you can offload some of the workloads that you would directly put on the h100 onto the mi30 and you will probably get get similar price performance right and if you can get away with less power at the cost of like longer run times because you don't care based on the workload you'll use the cheaper chip it's not like self-driving cars where one user tends to buy one car so the winner becomes a winner take all Market because why would you not buy the (17:50) best cheapest car in this case Tesla if a better chip comes along they're not like deleting server racks they're saying okay my next round of expansion I'm going to buy more of these I'm going to change my portfolio mix to be more like that I'm going to move towards a new goal as opposed to oh sell my old car buy a new car I still own exactly one car right one thing we should know about Nvidia if you Alex wanted to get an h100 tomorrow apparently there's a 12month lead time to get that so if AMD can get you something that's not quite as good but nearly as good in a shorter time period you might opt for that if (18:24) you want to buy a few of these and run your own business so that is why I feel as well at AMD will take a piece of that pie in 2024 they don't have to be the fastest they don't have to be the most power efficient or cheapest they they have a seat at the table and they will take some share out of this market so if AMD just says you're right nvidia's chips are 50% better than ours ours are 50% cheaper it's obviously not that simple because there's power considerations and physical data center footprint there's a pricing strategy element to all this not just a compute performance element right and then the (18:56) other thing I want to just point out before we before before we move on which I think is like super interesting how many emergency presentations have we seen this year where like even Apple got forced to make like a all of the sudden after qualcomm's presentation an emergency scary fast event and then after an Nvidia presentation we see an emergency AMD presentation and an emergency Intel presentations I think that was bananas that was not something that used to happen in the industry right like these events used to take months to plan prepare for people would rehearse their talks they would nail the words it's been pretty wild and that's (19:31) another function of all the speed right how fast things are yeah you're right that's that's a really good sounds like a really good recipe for some fun next year um so as we kind of wrap up the year I think the last kind of area we wanted to cover is the channel itself looking back at the the channel over the year we've had some changes she famously broke up with ar invest and we focused and really zoomed in on AI software companies semiconductors that was a key focus of the channel we came out with different formats as well the podcast that we're on right now more Super Cuts of specific events what do you really (20:05) want the tiemble you audience and Community take away from this changing direction and can you speak a little bit around the change in direction as well the breakup with Arc invest wasn't like some pre-planned thing right what actually happened was me and you erif decided to stick to our core competencies instead of go and mirror and comment on another portfolio manager Arin vest really does in my opinion have the best research and also in my opinion they're not that great let's just say at turning that research into investment decisions and we were very specific with what those investment decisions were (20:45) like dumping Nvidia right before it tripled or not recognizing the Innovations coming out of the Magnificent 7 there were a lot of these biases that showed up in their investment decisions seemingly because they just wanted to stay uncorrelated with the larger indexes but really that started affecting the way they're describing Innovation overall to the point where it didn't really jive with what me and you and our backgrounds were right so that that's really what drove us away from Arin at the same time I do want to stick to our core competencies I think AI software and Hardware me and you together do a really good job of (21:21) covering that space I do think that when Arc invest overlaps in that space especially for like Ark K Arc w and RQ those three funds I do want to cover their research more I've always said this I think they have some of the best research in the market space overall I just don't necessarily agree personally with how they turn that research into investment decisions and I think we've seen that this year when we broke up with ar invest we crushed it this year right like our biggest stock pick was Nvidia it more than tripled our second biggest stock pick was Microsoft Arvest doesn't hold any Microsoft and they (21:53) dumped a lot of Nvidia so we diverg from them pretty hard so you know we we'll keep doing more of that and aligning with them when it makes sense and not aligning with them when it doesn't and whoever wants to follow that Journey along the way can and for people who don't like our takes on the market there are plenty of other incredible content creators out there who have very different Frameworks for investing you know I think that's great we'd get a call and Alex would be like we're going to change direction we're like What again but uh no it made sense to be fair looking back you were right we double (22:21) down on like AI the AI area and chips and and you know the software side of it and that has been the focus of the last 12 months I mean to give people some know behind the scenes view I remember like me and you met in New Orleans and um I was jet lagged massively so my evenings by about 6 o'clock I was passing out but in the mornings I was buzzing so I was like buzzing I just had my coffee it was about 7 8 o'cl I was like Alex I've got this idea let's do this podcast and I was so confident for whatever reason that would be a really good idea I think it it might have been the coffee talk and you were like yeah (22:53) let's do it and then I remember about half an hour before we went live to record our first episode that that was when I started to doubt myself you've got such an established audience as a single person talking to camera I've been in the background up until now so I wasn't sure how it would go but yeah I just want to thank everyone for the feedback that they've shared the comments have been really helpful as well it's not you know they've been constructive as well about things you want to hear more of things you want us to focus on but we're going to keep doing this and yeah it's been a fun ride (23:19) and you know we're only on the first few episodes it'll be I'm sure we're going to come up with some really interesting content next year in this format as well yeah it's been great and and so there is one like contingent the audience that I really do want to acknowledge so we've pivoted pretty hard away from growth stocks towards stocks in areas that we have a lot of competence in uh and confidence in frankly um and there are people out there who wish we covered more hidden gems wish we covered smaller stocks with bigger growth opportunities and I really do understand and appreciate that I think now that (23:49) interest rates are scheduled to fall in 2024 and 2025 you can expect a little more of that from us but definitely in the areas that we already cover AI companies software of service companies semiconductor companies augmented in virtual reality I think as the channel has grown to nearly 300,000 subscribers it matters more to me that people are getting uh good information than exciting information right and so some of that pivot has been us maturing as a channel and as content creators and as people who care more about adding value Val to the audience than feeling valuable you know I think this year has really been hey what's best for the (24:36) audience how can we best serve the audience what ideas really make sense for the audience and that seemed to be focusing on the technologies that are really changing our lives at a Breakneck pace which is why we all of our favorite moments both on Hardware software you know in the stock market have been so focused on AI and I think the channel did an outstanding job of really hyperfocusing on that one thing thing taking our research turning it into investment decisions that we believe in and as a result you know that's what's responsible for the gains if you look at the types of stocks and their performance in 2021 and even some of (25:11) 2022 and then our performance post pivot it's night and day right so I think you know for those people who are looking for hidden gems you'll find them like we will cover them more in AI software and Hardware but our goal is always I think from really last year on to think of the audience first and not what's cool and exciting just for the sake of being cool and exciting I think there was a point in time when everyone was looking for growth stocks because interest rates were so low and they were looking for the next big thing and they were trying to really un uncover these hidden gems and it wasn't (25:44) just them it was VC companies were plowing Millions into these companies to try and get return on their money it was it was a different time and Co just exacerbated that and what is really interesting what you were just talking about there in terms of Arc invest inv in Innovation so one theme they're massive on is obviously AI being at the center of everything so they should have really benefited from the last 12 months why didn't they one is that they didn't believe that the mega caps were the place to get that benefit from Ai and I think they've been quite dogmatic about that haven't they like you said you're (26:16) not going to get exposed to the traditional stocks to the big things in the index is you're going to get something different you're going to get Innovation theks yeah and and I do think you know one thing that I found is true all good investors is they're willing to change their minds with new data right whether that's new interest rates whether that's just new technologies coming out if you're the same investor you were 10 years ago you're probably not a good investor and you might have a little bit of sou searching to do if you think what did well in 2020 and 2021 is the same thing that's going to do well (26:49) in 2024 and 2025 let alone 2030 and 2031 right the world is moving fast as this whole podcast episode has hopefully pointed out in Spades investors will need to learn how to move fast too and so I'm looking forward to our next episode where we talk about our predictions for 2024 I'm sure that episode will come out in December and by the end of January it'll be all wrong but like the idea there is are things moving too fast to even predict so I'm really excited for that episode too and with that until next time this is ticker symbol you my name is Alex and I'm joined by Arif reminding you that the (27:25) best investment you can make is in you Generate with Glarity.